<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

# ECCV2018

---

#### First Day (Sep 9th) Joint COCO and Mapilary Recognition Challenge Workshop
- COCO Detection
- COCO Panoptic
- COCO Keypoints
- COCO DensePose

Instance Segmentation
1）Edge Loss (Sigmoid), Group Norm
2) Global 
3) Two-pass (cascade rcnn, )
4) 2* version of detetron
5) Location-sensitive header

Panoptic Segmentation
1) Stuff
2) Object
object context network
supervison (multi-task ~1% performance improvement): object, object+stuff, stuff
multi-scale flip test
3) Post process
Residual L2 Loss (ce+l2)

Keypoints
1) Refine Net (Cascade Pyramid Netowrk)
2) L2 Loss
3) BackBone (Cascade: Lower->higher resolution) + Head ()
4) Cascade BackBone, skip connection across stages

Shangtang

1) hybrid task (det and seg branch): (cascade RCNN + mask RCNN)
2) guided anchoring (predict probability + aspect ratio)
3) FishNet(NIPS2018)
Tricks: Deform Conv SynBN

Keypoint
Taxonomy of Errors
image complexity: occulusion(visable points) and crowding(overlapping)
Easy images are saturated -> Need more challenging images
Previous work:
1)Stacked hourglass
2)CPN: Cascaded pyramid network (Last year winner)

Panopic Segmentation
1) Non-local module, se module, path aggregation
2) Label bank: predict non-exist label, multiply or merge

#### Oral (Sep 10th)
- Convolutional Networks with Adaptive Computation Graphs (Andreas Veit*, Cornell University; Serge Belongie, Cornell University)
- Progressive Neural Architecture Search (Chenxi Liu*, Johns Hopkins University; Maxim Neumann, Google; Barret Zoph, Google; Jon Shlens, Google; Wei Hua, Google; Li-Jia Li, Google; Li Fei-Fei, Stanford University; Alan Yuille, Johns Hopkins University; Jonathan Huang, Google; Kevin Murphy, Google
)
  - *CODE and MODEL*
  - The structures we discover in this way achieve state of the art classification accuracies on CIFAR-10 and ImageNet.
- Diverse Image-to-Image Translation via Disentangled Representations （Hsin-Ying Lee*, University of California, Merced; Hung-Yu Tseng, University of California, Merced; Maneesh Singh, Verisk Analytics; Jia-Bin Huang, Virginia Tech; Ming-Hsuan Yang, University of California at Merced）
  - Related work: Paired data (one to one mapping) and Unpaired data (Cycle)
  - Two main challenges for many applications: 1) the lack of aligned training pairs and 2) multiple possible outputs from a single input image.
  - Multi-modal mappig images onto two spaces (content and attributes): 1) a common content space capturing shared information across domains and 2) a domain-specific attribute space.
  - To handle unpaired training data, we propose a novel cross-cycle consistency based on disentangled representations. 
  - [Code and data]
- Lifting Layers: Analysis and Applications (Michael Moeller*, University of Siegen; Peter Ochs, Saarland University; Tim Meinhardt, Technical University of Munich; Laura Leal-Taixé, TUM)
- Learning with Biased Complementary Labels (Xiyu Yu*, The University of Sydney; Tongliang Liu, The University of Sydney; Mingming Gong, University of Pittsburgh; Dacheng Tao, University of Sydney)
  - Use easily obtainable surrogate for true labels, namely complementary
labels, which specify classes that observations do not belong to.
  - Given an observation in multi-class classification, identifying a class label that is incorrect for the observation is often much easier than identifying the true label.
  - ：）
 - Learning to Separate Object Sounds by Watching Unlabeled Video (Ruohan Gao*, University of Texas at Austin; Rogerio Feris, IBM Research; Kristen Grauman, University of Texas)
   - train on 100,000 multi-source video clips, then separate audio for novel video
 - End-to-End Joint Semantic Segmentation of Actors and Actions in Video (Jingwei Ji*, Stanford University; Shyamal Buch, Stanford University; Alvaro Soto, Universidad Catolica de Chile; Juan Carlos Niebles, Stanford University)
   - recognize actor-action pair
   - instance segmentation, action recognition and actor classification
   - actor and action: joint learning and decoupling (temporal 3D conv)
- Learning Discriminative Video Representations Using Adversarial Perturbations (Jue Wang*, ANU; Anoop Cherian, MERL)
  - Discriminative representation learning: separate input data X and noise set Z, subspace which span input data well
  - How to select noise set Z? Universal Adversarial Perturbations (UAP).
  - Cherian, A., Fernando, B., Harandi, M., Gould, S.: Generalized rank pooling for
activity recognition. In: CVPR (2017)

#### Oral (Sep 11th)

---
