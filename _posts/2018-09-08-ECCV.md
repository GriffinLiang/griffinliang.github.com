<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

# ECCV2018

---

#### First Day (Sep 9th) Joint COCO and Mapilary Recognition Challenge Workshop
- COCO Detection
- COCO Panoptic
- COCO Keypoints
- COCO DensePose

Instance Segmentation
1）Edge Loss (Sigmoid), Group Norm
2) Global 
3) Two-pass (cascade rcnn, )
4) 2* version of detetron
5) Location-sensitive header

Panoptic Segmentation
1) Stuff
2) Object
object context network
supervison (multi-task ~1% performance improvement): object, object+stuff, stuff
multi-scale flip test
3) Post process
Residual L2 Loss (ce+l2)

Keypoints
1) Refine Net (Cascade Pyramid Netowrk)
2) L2 Loss
3) BackBone (Cascade: Lower->higher resolution) + Head ()
4) Cascade BackBone, skip connection across stages

Shangtang

1) hybrid task (det and seg branch): (cascade RCNN + mask RCNN)
2) guided anchoring (predict probability + aspect ratio)
3) FishNet(NIPS2018)
Tricks: Deform Conv SynBN

Keypoint
Taxonomy of Errors
image complexity: occulusion(visable points) and crowding(overlapping)
Easy images are saturated -> Need more challenging images
Previous work:
1)Stacked hourglass
2)CPN: Cascaded pyramid network (Last year winner)

Panopic Segmentation
1) Non-local module, se module, path aggregation
2) Label bank: predict non-exist label, multiply or merge

#### Oral (Sep 10th)
- Convolutional Networks with Adaptive Computation Graphs (Andreas Veit*, Cornell University; Serge Belongie, Cornell University)
- Progressive Neural Architecture Search (Chenxi Liu*, Johns Hopkins University; Maxim Neumann, Google; Barret Zoph, Google; Jon Shlens, Google; Wei Hua, Google; Li-Jia Li, Google; Li Fei-Fei, Stanford University; Alan Yuille, Johns Hopkins University; Jonathan Huang, Google; Kevin Murphy, Google
)
  - *CODE and MODEL*
  - The structures we discover in this way achieve state of the art classification accuracies on CIFAR-10 and ImageNet.
- Diverse Image-to-Image Translation via Disentangled Representations （Hsin-Ying Lee*, University of California, Merced; Hung-Yu Tseng, University of California, Merced; Maneesh Singh, Verisk Analytics; Jia-Bin Huang, Virginia Tech; Ming-Hsuan Yang, University of California at Merced）
  - Related work: Paired data (one to one mapping) and Unpaired data (Cycle)
  - Two main challenges for many applications: 1) the lack of aligned training pairs and 2) multiple possible outputs from a single input image.
  - Multi-modal mappig images onto two spaces (content and attributes): 1) a common content space capturing shared information across domains and 2) a domain-specific attribute space.
  - To handle unpaired training data, we propose a novel cross-cycle consistency based on disentangled representations. 
  - [Code and data]
- Lifting Layers: Analysis and Applications (Michael Moeller*, University of Siegen; Peter Ochs, Saarland University; Tim Meinhardt, Technical University of Munich; Laura Leal-Taixé, TUM)
- Learning with Biased Complementary Labels (Xiyu Yu*, The University of Sydney; Tongliang Liu, The University of Sydney; Mingming Gong, University of Pittsburgh; Dacheng Tao, University of Sydney)
  - Use easily obtainable surrogate for true labels, namely complementary
labels, which specify classes that observations do not belong to.
  - Given an observation in multi-class classification, identifying a class label that is incorrect for the observation is often much easier than identifying the true label.
  - ：）
 - Learning to Separate Object Sounds by Watching Unlabeled Video (Ruohan Gao*, University of Texas at Austin; Rogerio Feris, IBM Research; Kristen Grauman, University of Texas)
   - train on 100,000 multi-source video clips, then separate audio for novel video
 - End-to-End Joint Semantic Segmentation of Actors and Actions in Video (Jingwei Ji*, Stanford University; Shyamal Buch, Stanford University; Alvaro Soto, Universidad Catolica de Chile; Juan Carlos Niebles, Stanford University)
   - recognize actor-action pair
   - instance segmentation, action recognition and actor classification
   - actor and action: joint learning and decoupling (temporal 3D conv)
- Learning Discriminative Video Representations Using Adversarial Perturbations (Jue Wang*, ANU; Anoop Cherian, MERL)
  - Discriminative representation learning: separate input data X and noise set Z, subspace which span input data well
  - How to select noise set Z? Universal Adversarial Perturbations (UAP).
  - Cherian, A., Fernando, B., Harandi, M., Gould, S.: Generalized rank pooling for
activity recognition. In: CVPR (2017)


#### Oral (Sep 11th)

- Predicting Gaze in Egocentric Video by Learning Task-dependent Attention Transition (Yifei Huang*, The University of Tokyo; Minjie Cai, Hunan University, The University of Tokyo; Zhenqiang Li, The University of Tokyo; Yoichi Sato,The University of Tokyo)
  - Motivation: high-level context of how a task is completed in a certain way has a strong influence on attention transition and should be modeled in natural dynamic
  - Method: task-dependent attention transition with bottomup saliency prediction is learned with a recurrent neural network to exploit the temporal context of gaze fixations.
- Instance-level Human Parsing via Part Grouping Network (Ke Gong*, SYSU; Xiaodan Liang, Carnegie Mellon University; Yicheng Li, Sun Yat-sen University; Yimin Chen, sensetime; Liang Lin, Sun Yat-sen University)
  - Baseline: Mask-RCNN fails to model the interaction between object intances.
  - Method: detection-free Part Grouping Network (PGN) for efficiently parsing multiple people in an image in a single pass (semantic part segmentation for assigning each pixel as a human part, instance-aware ** edge ** detection to group semantic parts into distinct person instances).
  - [CODE](http://sysu-hcp.net/lip/)

POSTER
- P-2A-12	Understanding Degeneracies and Ambiguities in Attribute Transfer
- P-2A-14	Rethinking the Form of Latent States in Image Captioning
- P-2A-15	ConvNets and ImageNet Beyond Accuracy: Understanding Mistakes and Uncovering Biases

#### Oral (Sep 13th)

- Group Normalization (Yuxin Wu, Facebook; Kaiming He*, Facebook Inc., USA)
  - Normalization matters, batch is not always ideal (Small Batch), channels can be grouped and have substructures
  - GN enables training Mask R-CNN from scratch (~1% performance decrease)
- Deep Expander Networks: Efficient Deep Networks from Graph Theory (Ameya Prabhu*, IIIT Hyderabad; Girish Varma, IIIT Hyderabad; Anoop Namboodiri, IIIT Hyderbad)
  - compare with group conv, pruning, ResNet-XResNet
  - [CODE](https://github.com/DrImpossible/Deep-Expander-Networks)
- Towards Realistic Predictors (Pei Wang*, UC San Diego; Nuno Vasconcelos, UC San Diego)
  - analyze the difficulty of each task (realism)
  - reject to perfrom the hard task and request additional information
  - adversarial learning
  - [link](http://www.svcl.ucsd.edu/~peiwang/) and CODE
- Learning SO(3) Equivariant Representations with Spherical CNNs (Carlos Esteves*, University of Pennsylvania; Kostas Daniilidis, University of Pennsylvania; Ameesh Makadia, Google Research; Christine Allec-Blanchette, University of Pennsylvania)
  - equivariance
  - spherical convolutions
  - pooling and parameterization of filters in the spectral domain,
with enforced spatial localization and capacity independent of the resolution
 - CODE

---
